# arxiv-daily latest papers around hine arxiv daily paper
Automated deployment @ 2023-06-09 20:50:11 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`]({repo_url}/blob/main/database/topic.yml).
> You can also view historical data through the [storage]({repo_url}/blob/main/database/storage).

## HINE

### hine
|Publish Date|Title|Authors|PDF|Code|Abstract|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2023-06-08**|**Design of Sturm global attractors 2: Time-reversible Chafee-Infante lattices of 3-nose meanders**|Bernold Fiedler et.al.|[2306.05232v1](http://arxiv.org/abs/2306.05232v1)|null|This sequel continues our exploration arxiv:2302.12531 of a deceptively ``simple'' class of global attractors, called Sturm due to nodal properties. They arise for the semilinear scalar parabolic PDE   \begin{equation}\label{eq:*}   u_t = u_{xx} + f(x,u,u_x) \tag{$*$}   \end{equation} on the unit interval $0 < x<1$, under Neumann boundary conditions. This models the interplay of reaction, advection, and diffusion.   Our classification is based on the Sturm meanders, which arise from a shooting approach to the ODE boundary value problem of equilibrium solutions $u=v(x)$. Specifically, we address meanders with only three ``noses'', each of which is innermost to a nested family of upper or lower meander arcs. The Chafee-Infante paradigm of 1974, with cubic nonlinearity $f=f(u)$, features just two noses.   We present, and fully prove, a precise description of global PDE connection graphs, graded by Morse index, for such gradient-like Morse-Smale systems \eqref{eq:*}. The directed edges denote PDE heteroclinic orbits $v_1 \leadsto v_2$ between equilibrium vertices $v_1, v_2$ of adjacent Morse index. The connection graphs can be described as a lattice-like structure of Chafee-Infante subgraphs. However, this simple description requires us to adjoin a single ``equilibrium'' vertex, formally, at Morse level -1. Surprisingly, for parabolic PDEs based on irreversible diffusion, the connection graphs then also exhibit global time reversibility.|
|**2023-06-05**|**Neural Networks from Biological to Artificial and Vice Versa**|Abdullatif Baba et.al.|[2306.04449v1](http://arxiv.org/abs/2306.04449v1)|null|In this paper, we examine how deep learning can be utilized to investigate neural health and the difficulties in interpreting neurological analyses within algorithmic models. The key contribution of this paper is the investigation of the impact of a dead neuron on the performance of artificial neural networks (ANNs). Therefore, we conduct several tests using different training algorithms and activation functions to identify the precise influence of the training process on neighboring neurons and the overall performance of the ANN in such cases. The aim is to assess the potential application of the findings in the biological domain, the expected results may have significant implications for the development of effective treatment strategies for neurological disorders. Successive training phases that incorporate visual and acoustic data derived from past social and familial experiences could be suggested to achieve this goal. Finally, we explore the conceptual analogy between the Adam optimizer and the learning process of the brain by delving into the specifics of both systems while acknowledging their fundamental differences.|
|**2023-06-02**|**BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models**|Marvin Lavechin et.al.|[2306.01506v2](http://arxiv.org/abs/2306.01506v2)|[link](https://github.com/marvinlvn/babyslm)|Self-supervised techniques for learning speech representations have been shown to develop linguistic competence from exposure to speech without the need for human labels. In order to fully realize the potential of these approaches and further our understanding of how infants learn language, simulations must closely emulate real-life situations by training on developmentally plausible corpora and benchmarking against appropriate test sets. To this end, we propose a language-acquisition-friendly benchmark to probe spoken language models at the lexical and syntactic levels, both of which are compatible with the vocabulary typical of children's language experiences. This paper introduces the benchmark and summarizes a range of experiments showing its usefulness. In addition, we highlight two exciting challenges that need to be addressed for further progress: bridging the gap between text and speech and between clean speech and in-the-wild speech.|
|**2023-06-01**|**Generalizability analyses with a partially nested trial design: the Necrotizing Enterocolitis Surgery Trial**|Sarah E. Robertson et.al.|[2306.00855v1](http://arxiv.org/abs/2306.00855v1)|null|We discuss generalizability analyses under a partially nested trial design, where part of the trial is nested within a cohort of trial-eligible individuals, while the rest of the trial is not nested. This design arises, for example, when only some centers participating in a trial are able to collect data on non-randomized individuals, or when data on non-randomized individuals cannot be collected for the full duration of the trial. Our work is motivated by the Necrotizing Enterocolitis Surgery Trial (NEST) that compared initial laparotomy versus peritoneal drain for infants with necrotizing enterocolitis or spontaneous intestinal perforation. During the first phase of the study, data were collected from randomized individuals as well as consenting non-randomized individuals; during the second phase of the study, however, data were only collected from randomized individuals, resulting in a partially nested trial design. We propose methods for generalizability analyses with partially nested trial designs. We describe identification conditions and propose estimators for causal estimands in the target population of all trial-eligible individuals, both randomized and non-randomized, in the part of the data where the trial is nested, while using trial information spanning both parts. We evaluate the estimators in a simulation study.|
|**2023-06-01**|**Interpretable simultaneous localization of MRI corpus callosum and classification of atypical Parkinsonian disorders using YOLOv5**|Vamshi Krishna Kancharla et.al.|[2306.00473v1](http://arxiv.org/abs/2306.00473v1)|null|Structural MRI(S-MRI) is one of the most versatile imaging modality that revolutionized the anatomical study of brain in past decades. The corpus callosum (CC) is the principal white matter fibre tract, enabling all kinds of inter-hemispheric communication. Thus, subtle changes in CC might be associated with various neurological disorders. The present work proposes the potential of YOLOv5-based CC detection framework to differentiate atypical Parkinsonian disorders (PD) from healthy controls (HC). With 3 rounds of hold-out validation, mean classification accuracy of 92% is obtained using the proposed method on a proprietary dataset consisting of 20 healthy subjects and 20 cases of APDs, with an improvement of 5% over SOTA methods (CC morphometry and visual texture analysis) that used the same dataset. Subsequently, in order to incorporate the explainability of YOLO predictions, Eigen CAM based heatmap is generated for identifying the most important sub-region in CC that leads to the classification. The result of Eigen CAM showed CC mid-body as the most distinguishable sub-region in classifying APDs and HC, which is in-line with SOTA methodologies and the current prevalent understanding in medicine.|
|**2023-05-31**|**Computational Language Assessment in patients with speech, language, and communication impairments**|Charalambos Themistocleous et.al.|[2305.20046v1](http://arxiv.org/abs/2305.20046v1)|null|Speech, language, and communication symptoms enable the early detection, diagnosis, treatment planning, and monitoring of neurocognitive disease progression. Nevertheless, traditional manual neurologic assessment, the speech and language evaluation standard, is time-consuming and resource-intensive for clinicians. We argue that Computational Language Assessment (C.L.A.) is an improvement over conventional manual neurological assessment. Using machine learning, natural language processing, and signal processing, C.L.A. provides a neuro-cognitive evaluation of speech, language, and communication in elderly and high-risk individuals for dementia. ii. facilitates the diagnosis, prognosis, and therapy efficacy in at-risk and language-impaired populations; and iii. allows easier extensibility to assess patients from a wide range of languages. Also, C.L.A. employs Artificial Intelligence models to inform theory on the relationship between language symptoms and their neural bases. It significantly advances our ability to optimize the prevention and treatment of elderly individuals with communication disorders, allowing them to age gracefully with social engagement.|
|**2023-05-28**|**A joint estimation approach for monotonic regression functions in general dimensions**|Christian Rohrbeck et.al.|[2305.17711v1](http://arxiv.org/abs/2305.17711v1)|null|Regression analysis under the assumption of monotonicity is a well-studied statistical problem and has been used in a wide range of applications. However, there remains a lack of a broadly applicable methodology that permits information borrowing, for efficiency gains, when jointly estimating multiple monotonic regression functions. We introduce such a methodology by extending the isotonic regression problem presented in the article "The isotonic regression problem and its dual" (Barlow and Brunk, 1972). The presented approach can be applied to both fixed and random designs and any number of explanatory variables (regressors). Our framework penalizes pairwise differences in the values (levels) of the monotonic function estimates, with the weight of penalty being determined based on a statistical test, which results in information being shared across data sets if similarities in the regression functions exist. Function estimates are subsequently derived using an iterative optimization routine that uses existing solution algorithms for the isotonic regression problem. Simulation studies for normally and binomially distributed response data illustrate that function estimates are consistently improved if similarities between functions exist, and are not oversmoothed otherwise. We further apply our methodology to analyse two public health data sets: neonatal mortality data for Porto Alegre, Brazil, and stroke patient data for North West England.|
|**2023-05-27**|**Explainable Brain Age Prediction using coVariance Neural Networks**|Saurabh Sihag et.al.|[2305.18370v1](http://arxiv.org/abs/2305.18370v1)|[link](https://github.com/pennbindlab/vnn_brain_age)|In computational neuroscience, there has been an increased interest in developing machine learning algorithms that leverage brain imaging data to provide estimates of "brain age" for an individual. Importantly, the discordance between brain age and chronological age (referred to as "brain age gap") can capture accelerated aging due to adverse health conditions and therefore, can reflect increased vulnerability towards neurological disease or cognitive impairments. However, widespread adoption of brain age for clinical decision support has been hindered due to lack of transparency and methodological justifications in most existing brain age prediction algorithms. In this paper, we leverage coVariance neural networks (VNN) to propose an anatomically interpretable framework for brain age prediction using cortical thickness features. Specifically, our brain age prediction framework extends beyond the coarse metric of brain age gap in Alzheimer's disease (AD) and we make two important observations: (i) VNNs can assign anatomical interpretability to elevated brain age gap in AD by identifying contributing brain regions, (ii) the interpretability offered by VNNs is contingent on their ability to exploit specific eigenvectors of the anatomical covariance matrix. Together, these observations facilitate an explainable perspective to the task of brain age prediction.|
|**2023-05-25**|**Emergence of a phonological bias in ChatGPT**|Juan Manuel Toro et.al.|[2305.15929v2](http://arxiv.org/abs/2305.15929v2)|null|Current large language models, such as OpenAI's ChatGPT, have captured the public's attention because how remarkable they are in the use of language. Here, I demonstrate that ChatGPT displays phonological biases that are a hallmark of human language processing. More concretely, just like humans, ChatGPT has a consonant bias. That is, the chatbot has a tendency to use consonants over vowels to identify words. This is observed across languages that differ in their relative distribution of consonants and vowels such as English and Spanish. Despite the differences in how current artificial intelligence language models are trained to process linguistic stimuli and how human infants acquire language, such training seems to be enough for the emergence of a phonological bias in ChatGPT|
|**2023-05-24**|**From Interactive to Co-Constructive Task Learning**|Anna-Lisa Vollmer et.al.|[2305.15535v1](http://arxiv.org/abs/2305.15535v1)|null|Humans have developed the capability to teach relevant aspects of new or adapted tasks to a social peer with very few task demonstrations by making use of scaffolding strategies that leverage prior knowledge and importantly prior joint experience to yield a joint understanding and a joint execution of the required steps to solve the task. This process has been discovered and analyzed in parent-infant interaction and constitutes a ``co-construction'' as it allows both, the teacher and the learner, to jointly contribute to the task. We propose to focus research in robot interactive learning on this co-construction process to enable robots to learn from non-expert users in everyday situations. In the following, we will review current proposals for interactive task learning and discuss their main contributions with respect to the entailing interaction. We then discuss our notion of co-construction and summarize research insights from adult-child and human-robot interactions to elucidate its nature in more detail. From this overview we finally derive research desiderata that entail the dimensions architecture, representation, interaction and explainability.|
|**2023-05-23**|**ECCENTRIC: a fast and unrestrained approach for high-resolution in vivo metabolic imaging at ultra-high field MR**|Antoine Klauser et.al.|[2305.13822v1](http://arxiv.org/abs/2305.13822v1)|null|A novel method for fast and high-resolution metabolic imaging, called ECcentric Circle ENcoding TRajectorIes for Compressed sensing (ECCENTRIC), has been developed and implemented on 7 Tesla human MRI. ECCENTRIC is a non-Cartesian spatial-spectral encoding method optimized for random undersampling of magnetic resonance spectroscopic imaging (MRSI) at ultra-high field. The approach provides flexible and random (k,t) sampling without temporal interleaving to improve spatial response function and spectral quality. ECCENTRIC needs low gradient amplitudes and slew-rates that reduces electrical, mechanical and thermal stress of the scanner hardware, and is robust to timing imperfection and eddy-current delays. Combined with a model-based low-rank reconstruction, this approach enables simultaneous imaging of up to 14 metabolites over the whole-brain at 2-3mm isotropic resolution in 4-10 minutes with high signal-to-noise ratio. In 20 healthy volunteers and 20 glioma patients ECCENTRIC demonstrated unprecedented mapping of fine structural details of metabolism in healthy brains and an extended metabolic fingerprinting of glioma tumors.|
|**2023-05-22**|**Developmental Curiosity and Social Interaction in Virtual Agents**|Chris Doyle et.al.|[2305.13396v1](http://arxiv.org/abs/2305.13396v1)|null|Infants explore their complex physical and social environment in an organized way. To gain insight into what intrinsic motivations may help structure this exploration, we create a virtual infant agent and place it in a developmentally-inspired 3D environment with no external rewards. The environment has a virtual caregiver agent with the capability to interact contingently with the infant agent in ways that resemble play. We test intrinsic reward functions that are similar to motivations that have been proposed to drive exploration in humans: surprise, uncertainty, novelty, and learning progress. These generic reward functions lead the infant agent to explore its environment and discover the contingencies that are embedded into the caregiver agent. The reward functions that are proxies for novelty and uncertainty are the most successful in generating diverse experiences and activating the environment contingencies. We also find that learning a world model in the presence of an attentive caregiver helps the infant agent learn how to predict scenarios with challenging social and physical dynamics. Taken together, our findings provide insight into how curiosity-like intrinsic rewards and contingent social interaction lead to dynamic social behavior and the creation of a robust predictive world model.|
|**2023-05-21**|**Towards Robust Family-Infant Audio Analysis Based on Unsupervised Pretraining of Wav2vec 2.0 on Large-Scale Unlabeled Family Audio**|Jialu Li et.al.|[2305.12530v2](http://arxiv.org/abs/2305.12530v2)|null|To perform automatic family audio analysis, past studies have collected recordings using phone, video, or audio-only recording devices like LENA, investigated supervised learning methods, and used or fine-tuned general-purpose embeddings learned from large pretrained models. In this study, we advance the audio component of a new infant wearable multi-modal device called LittleBeats (LB) by learning family audio representation via wav2vec 2.0 (W2V2) pertaining. We show given a limited number of labeled LB home recordings, W2V2 pretrained using 1k-hour of unlabeled home recordings outperforms oracle W2V2 pretrained on 52k-hour unlabeled audio in terms of parent/infant speaker diarization (SD) and vocalization classifications (VC) at home. Extra relevant external unlabeled and labeled data further benefit W2V2 pretraining and fine-tuning. With SpecAug and environmental speech corruptions, we obtain 12% relative gain on SD and moderate boost on VC. Code and model weights are available.|
|**2023-05-18**|**Federated learning for secure development of AI models for Parkinson's disease detection using speech from different languages**|Soroosh Tayebi Arasteh et.al.|[2305.11284v1](http://arxiv.org/abs/2305.11284v1)|null|Parkinson's disease (PD) is a neurological disorder impacting a person's speech. Among automatic PD assessment methods, deep learning models have gained particular interest. Recently, the community has explored cross-pathology and cross-language models which can improve diagnostic accuracy even further. However, strict patient data privacy regulations largely prevent institutions from sharing patient speech data with each other. In this paper, we employ federated learning (FL) for PD detection using speech signals from 3 real-world language corpora of German, Spanish, and Czech, each from a separate institution. Our results indicate that the FL model outperforms all the local models in terms of diagnostic accuracy, while not performing very differently from the model based on centrally combined training sets, with the advantage of not requiring any data sharing among collaborators. This will simplify inter-institutional collaborations, resulting in enhancement of patient outcomes.|
|**2023-05-18**|**Comparing Machines and Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA Responses**|Eliza Kosoy et.al.|[2305.11243v1](http://arxiv.org/abs/2305.11243v1)|null|Developmental psychologists have spent decades devising experiments to test the intelligence and knowledge of infants and children, tracing the origin of crucial concepts and capacities. Moreover, experimental techniques in developmental psychology have been carefully designed to discriminate the cognitive capacities that underlie particular behaviors. We propose that using classical experiments from child development is a particularly effective way to probe the computational abilities of AI models, in general, and LLMs in particular. First, the methodological techniques of developmental psychology, such as the use of novel stimuli to control for past experience or control conditions to determine whether children are using simple associations, can be equally helpful for assessing the capacities of LLMs. In parallel, testing LLMs in this way can tell us whether the information that is encoded in text is sufficient to enable particular responses, or whether those responses depend on other kinds of information, such as information from exploration of the physical world. In this work we adapt classical developmental experiments to evaluate the capabilities of LaMDA, a large language model from Google. We propose a novel LLM Response Score (LRS) metric which can be used to evaluate other language models, such as GPT. We find that LaMDA generates appropriate responses that are similar to those of children in experiments involving social understanding, perhaps providing evidence that knowledge of these domains is discovered through language. On the other hand, LaMDA's responses in early object and action understanding, theory of mind, and especially causal reasoning tasks are very different from those of young children, perhaps showing that these domains require more real-world, self-initiated exploration and cannot simply be learned from patterns in language input.|
|**2023-05-18**|**Client Selection for Federated Policy Optimization with Environment Heterogeneity**|Zhijie Xie et.al.|[2305.10978v3](http://arxiv.org/abs/2305.10978v3)|null|The development of Policy Iteration (PI) has inspired many recent algorithms for Reinforcement Learning (RL), including several policy gradient methods, that gained both theoretical soundness and empirical success on a variety of tasks. The theory of PI is rich in the context of centralized learning, but its study is still in the infant stage under the federated setting. This paper explores the federated version of Approximate PI (API) and derives its error bound, taking into account the approximation error introduced by environment heterogeneity. We theoretically prove that a proper client selection scheme can reduce this error bound. Based on the theoretical result, we propose a client selection algorithm to alleviate the additional approximation error caused by environment heterogeneity. Experiment results show that the proposed algorithm outperforms other biased and unbiased client selection methods on the federated mountain car problem by effectively selecting clients with a lower level of heterogeneity from the population distribution.|
|**2023-05-17**|**Transcending Grids: Point Clouds and Surface Representations Powering Neurological Processing**|Kishore Babu Nampalle et.al.|[2305.15426v2](http://arxiv.org/abs/2305.15426v2)|null|In healthcare, accurately classifying medical images is vital, but conventional methods often hinge on medical data with a consistent grid structure, which may restrict their overall performance. Recent medical research has been focused on tweaking the architectures to attain better performance without giving due consideration to the representation of data. In this paper, we present a novel approach for transforming grid based data into its higher dimensional representations, leveraging unstructured point cloud data structures. We first generate a sparse point cloud from an image by integrating pixel color information as spatial coordinates. Next, we construct a hypersurface composed of points based on the image dimensions, with each smooth section within this hypersurface symbolizing a specific pixel location. Polygonal face construction is achieved using an adjacency tensor. Finally, a dense point cloud is generated by densely sampling the constructed hypersurface, with a focus on regions of higher detail. The effectiveness of our approach is demonstrated on a publicly accessible brain tumor dataset, achieving significant improvements over existing classification techniques. This methodology allows the extraction of intricate details from the original image, opening up new possibilities for advanced image analysis and processing tasks.|
|**2023-05-17**|**Analyzing the Stance of Facebook Posts on Abortion Considering State-level Health and Social Compositions**|Ana Aleksandric et.al.|[2305.09889v1](http://arxiv.org/abs/2305.09889v1)|null|Abortion remains one of the most controversial topics, especially after overturning Roe v. Wade ruling in the United States. Previous literature showed that the illegality of abortion could have serious consequences, as women might seek unsafe pregnancy terminations leading to increased maternal mortality rates and negative effects on their reproductive health. Therefore, the stances of the abortion-related Facebook posts were analyzed at the state level in the United States from May 4 until June 30, 2022, right after the Supreme Court's decision was disclosed. In more detail, the pre-trained Transformer architecture-based model was fine-tuned on a manually labeled training set to obtain a stance detection model suitable for the collected dataset. Afterward, we employed appropriate statistical tests to examine the relationships between public opinion regarding abortion, abortion legality, political leaning, and factors measuring the overall population's health, health knowledge, and vulnerability per state. We found that states with a higher number of views against abortion also have higher infant and maternal mortality rates. Furthermore, the stance of social media posts per state is mostly matching with the current abortion laws in these states. While aligned with existing literature, these findings indicate how public opinion, laws, and women's and infants' health are related, and interventions are required to educate and protect women, especially in vulnerable populations.|
|**2023-05-16**|**Evaluation of self-supervised pre-training for automatic infant movement classification using wearable movement sensors**|Einari Vaaras et.al.|[2305.09366v1](http://arxiv.org/abs/2305.09366v1)|null|The recently-developed infant wearable MAIJU provides a means to automatically evaluate infants' motor performance in an objective and scalable manner in out-of-hospital settings. This information could be used for developmental research and to support clinical decision-making, such as detection of developmental problems and guiding of their therapeutic interventions. MAIJU-based analyses rely fully on the classification of infant's posture and movement; it is hence essential to study ways to increase the accuracy of such classifications, aiming to increase the reliability and robustness of the automated analysis. Here, we investigated how self-supervised pre-training improves performance of the classifiers used for analyzing MAIJU recordings, and we studied whether performance of the classifier models is affected by context-selective quality-screening of pre-training data to exclude periods of little infant movement or with missing sensors. Our experiments show that i) pre-training the classifier with unlabeled data leads to a robust accuracy increase of subsequent classification models, and ii) selecting context-relevant pre-training data leads to substantial further improvements in the classifier performance.|
|**2023-05-16**|**Health Impacts of Public Pawnshops in Industrializing Tokyo**|Tatsuki Inoue et.al.|[2305.09352v1](http://arxiv.org/abs/2305.09352v1)|null|This study is the first to investigate whether financial institutions for low-income populations have contributed to the historical decline in mortality rates. Using ward-level panel data from prewar Tokyo City, we found that public pawn loans were associated with reductions in infant and fetal death rates, potentially through improved nutrition and hygiene measures. Simple calculations suggest that popularizing public pawnshops led to a 6% and 8% decrease in infant mortality and fetal death rates, respectively, from 1927 to 1935. Contrarily, private pawnshops showed no significant association with health improvements. Our findings enrich the expanding literature on demographics and financial histories.|
|**2023-05-16**|**A Wearable Wireless Magnetic Eye-Tracker, in-vitro and in-vivo Tests**|Giuseppe Bevilacqua et.al.|[2305.09289v1](http://arxiv.org/abs/2305.09289v1)|null|A wireless, wearable magnetic eye tracker is described and characterized. The proposed instrumentation enables simultaneous evaluation of eye and head angular displacements. Such a system can be used to determine the absolute gaze direction as well as to analyze spontaneous eye re-orientation in response to stimuli consisting in head rotations. The latter feature has implications to analyze the vestibulo-ocular reflex and constitutes an interesting opportunity to develop medical (oto-neurological) diagnostics. Details of data analysis are reported together with some results obtained in-vivo or with simple mechanical simulators that enable measurements under controlled conditions.|
|**2023-05-15**|**Towards personalised music-therapy; a neurocomputational modelling perspective**|Nicole Lai et.al.|[2305.14364v1](http://arxiv.org/abs/2305.14364v1)|null|Music therapy has emerged recently as a successful intervention that improves patient's outcome in a large range of neurological and mood disorders without adverse effects. Brain networks are entrained to music in ways that can be explained both via top-down and bottom-up processes. In particular, the direct interaction of auditory with the motor and the reward system via a predictive framework explains the efficacy of music-based interventions in motor rehabilitation. In this manuscript, we provide a brief overview of current theories of music perception and processing. Subsequently, we summarise evidence of music-based interventions primarily in motor, emotional and cardiovascular regulation. We highlight opportunities to improve quality of life and reduce stress beyond the clinic environment and in healthy individuals. This relatively unexplored area requires an understanding of how we can personalise and automate music selection processes to fit individuals needs and tasks via feedback loops mediated by measurements of neuro-physiological responses.|
|**2023-05-10**|**Direct Estimation of Pupil Parameters Using Deep Learning for Visible Light Pupillometry**|Abhijeet Phatak et.al.|[2305.06425v1](http://arxiv.org/abs/2305.06425v1)|null|Pupil reflex to variations in illumination and associated dynamics are of importance in neurology and ophthalmology. This is typically measured using a near Infrared (IR) pupillometer to avoid Purkinje reflections that appear when strong Visible Light (VL) illumination is present. Previously we demonstrated the use of deep learning techniques to accurately detect the pupil pixels (segmentation mask) in case of VL images for performing VL pupillometry. Here, we present a method to obtain the parameters of the elliptical pupil boundary along with the segmentation mask is presented. This eliminates the need for an additional, computationally expensive post-processing step of ellipse fitting and also improves segmentation accuracy. Using the time-varying ellipse parameters of pupil, we can compute the dynamics of the Pupillary Light Reflex (PLR). We also present preliminary evaluations of our deep-learning algorithms on clinical data. This work is a significant push in our goal to develop and validate a VL pupillometer based on a smartphone that can be used in the field.|
|**2023-05-10**|**A Method to Automate the Discharge Summary Hospital Course for Neurology Patients**|Vince C. Hartman et.al.|[2305.06416v1](http://arxiv.org/abs/2305.06416v1)|null|Generation of automated clinical notes have been posited as a strategy to mitigate physician burnout. In particular, an automated narrative summary of a patient's hospital stay could supplement the hospital course section of the discharge summary that inpatient physicians document in electronic health record (EHR) systems. In the current study, we developed and evaluated an automated method for summarizing the hospital course section using encoder-decoder sequence-to-sequence transformer models. We fine tuned BERT and BART models and optimized for factuality through constraining beam search, which we trained and tested using EHR data from patients admitted to the neurology unit of an academic medical center. The approach demonstrated good ROUGE scores with an R-2 of 13.76. In a blind evaluation, two board-certified physicians rated 62% of the automated summaries as meeting the standard of care, which suggests the method may be useful clinically. To our knowledge, this study is among the first to demonstrate an automated method for generating a discharge summary hospital course that approaches a quality level of what a physician would write.|
|**2023-05-10**|**Autonomous Stabilization of Retinal Videos for Streamlining Assessment of Spontaneous Venous Pulsations**|Hongwei Sheng et.al.|[2305.06043v1](http://arxiv.org/abs/2305.06043v1)|null|Spontaneous retinal Venous Pulsations (SVP) are rhythmic changes in the caliber of the central retinal vein and are observed in the optic disc region (ODR) of the retina. Its absence is a critical indicator of various ocular or neurological abnormalities. Recent advances in imaging technology have enabled the development of portable smartphone-based devices for observing the retina and assessment of SVPs. However, the quality of smartphone-based retinal videos is often poor due to noise and image jitting, which in return, can severely obstruct the observation of SVPs. In this work, we developed a fully automated retinal video stabilization method that enables the examination of SVPs captured by various mobile devices. Specifically, we first propose an ODR Spatio-Temporal Localization (ODR-STL) module to localize visible ODR and remove noisy and jittering frames. Then, we introduce a Noise-Aware Template Matching (NATM) module to stabilize high-quality video segments at a fixed position in the field of view. After the processing, the SVPs can be easily observed in the stabilized videos, significantly facilitating user observations. Furthermore, our method is cost-effective and has been tested in both subjective and objective evaluations. Both of the evaluations support its effectiveness in facilitating the observation of SVPs. This can improve the timely diagnosis and treatment of associated diseases, making it a valuable tool for eye health professionals.|
|**2023-05-09**|**Child Palm-ID: Contactless Palmprint Recognition for Children**|Akash Godbole et.al.|[2305.05161v1](http://arxiv.org/abs/2305.05161v1)|null|Effective distribution of nutritional and healthcare aid for children, particularly infants and toddlers, in some of the least developed and most impoverished countries of the world, is a major problem due to the lack of reliable identification documents. Biometric authentication technology has been investigated to address child recognition in the absence of reliable ID documents. We present a mobile-based contactless palmprint recognition system, called Child Palm-ID, which meets the requirements of usability, hygiene, cost, and accuracy for child recognition. Using a contactless child palmprint database, Child-PalmDB1, consisting of 19,158 images from 1,020 unique palms (in the age range of 6 mos. to 48 mos.), we report a TAR=94.11% @ FAR=0.1%. The proposed Child Palm-ID system is also able to recognize adults, achieving a TAR=99.4% on the CASIA contactless palmprint database and a TAR=100% on the COEP contactless adult palmprint database, both @ FAR=0.1%. These accuracies are competitive with the SOTA provided by COTS systems. Despite these high accuracies, we show that the TAR for time-separated child-palmprints is only 78.1% @ FAR=0.1%.|
|**2023-05-07**|**Lightweight Convolution Transformer for Cross-patient Seizure Detection in Multi-channel EEG Signals**|Salim Rukhsar et.al.|[2305.04325v1](http://arxiv.org/abs/2305.04325v1)|null|Background: Epilepsy is a neurological illness affecting the brain that makes people more likely to experience frequent, spontaneous seizures. There has to be an accurate automated method for measuring seizure frequency and severity in order to assess the efficacy of pharmacological therapy for epilepsy. The drug quantities are often derived from patient reports which may cause significant issues owing to inadequate or inaccurate descriptions of seizures and their frequencies. Methods and materials: This study proposes a novel deep learning architecture based lightweight convolution transformer (LCT). The transformer is able to learn spatial and temporal correlated information simultaneously from the multi-channel electroencephalogram (EEG) signal to detect seizures at smaller segment lengths. In the proposed model, the lack of translation equivariance and localization of ViT is reduced using convolution tokenization, and rich information from the transformer encoder is extracted by sequence pooling instead of the learnable class token. Results: Extensive experimental results demonstrate that the proposed model of cross-patient learning can effectively detect seizures from the raw EEG signals. The accuracy and F1-score of seizure detection in the cross-patient case on the CHB-MIT dataset are shown to be 96.31% and 96.32%, respectively, at 0.5 sec segment length. In addition, the performance metrics show that the inclusion of inductive biases and attention-based pooling in the model enhances the performance and reduces the number of transformer encoder layers, which significantly reduces the computational complexity. In this research work, we provided a novel approach to enhance efficiency and simplify the architecture for multi-channel automated seizure detection.|
|**2023-05-05**|**Uncertainty Quantification for Fisher-Kolmogorov Equation on Graphs with Application to Patient-Specific Alzheimer Disease**|Mattia Corti et.al.|[2305.03619v1](http://arxiv.org/abs/2305.03619v1)|null|The Fisher-Kolmogorov equation is a diffusion-reaction PDE that is used to model the accumulation of prionic proteins, which are responsible for many different neurological disorders. Likely, the most important and studied misfolded protein in literature is the Amyloid-$\beta$, responsible for the onset of Alzheimer disease. Starting from medical images we construct a reduced-order model based on a graph brain connectome. The reaction coefficient of the proteins is modelled as a stochastic random field, taking into account all the many different underlying physical processes, which can hardly be measured. Its probability distribution is inferred by means of the Monte Carlo Markov Chain method applied to clinical data. The resulting model is patient-specific and can be employed for predicting the disease's future development. Forward uncertainty quantification techniques (Monte Carlo and sparse grid stochastic collocation) are applied with the aim of quantifying the impact of the variability of the reaction coefficient on the progression of protein accumulation within the next 20 years.|
|**2023-05-04**|**Mining fMRI Dynamics with Parcellation Prior for Brain Disease Diagnosis**|Xiaozhao Liu et.al.|[2305.03061v1](http://arxiv.org/abs/2305.03061v1)|null|To characterize atypical brain dynamics under diseases, prevalent studies investigate functional magnetic resonance imaging (fMRI). However, most of the existing analyses compress rich spatial-temporal information as the brain functional networks (BFNs) and directly investigate the whole-brain network without neurological priors about functional subnetworks. We thus propose a novel graph learning framework to mine fMRI signals with topological priors from brain parcellation for disease diagnosis. Specifically, we 1) detect diagnosis-related temporal features using a "Transformer" for a higher-level BFN construction, and process it with a following graph convolutional network, and 2) apply an attention-based multiple instance learning strategy to emphasize the disease-affected subnetworks to further enhance the diagnosis performance and interpretability. Experiments demonstrate higher effectiveness of our method than compared methods in the diagnosis of early mild cognitive impairment. More importantly, our method is capable of localizing crucial brain subnetworks during the diagnosis, providing insights into the pathogenic source of mild cognitive impairment.|
|**2023-05-03**|**Analysing the Impact of Audio Quality on the Use of Naturalistic Long-Form Recordings for Infant-Directed Speech Research**|María Andrea Cruz Blandón et.al.|[2305.01965v1](http://arxiv.org/abs/2305.01965v1)|[link](https://github.com/SPEECHCOG/ids_audio_quality_analysis)|Modelling of early language acquisition aims to understand how infants bootstrap their language skills. The modelling encompasses properties of the input data used for training the models, the cognitive hypotheses and their algorithmic implementations being tested, and the evaluation methodologies to compare models to human data. Recent developments have enabled the use of more naturalistic training data for computational models. This also motivates development of more naturalistic tests of model behaviour. A crucial step towards such an aim is to develop representative speech datasets consisting of speech heard by infants in their natural environments. However, a major drawback of such recordings is that they are typically noisy, and it is currently unclear how the sound quality could affect analyses and modelling experiments conducted on such data. In this paper, we explore this aspect for the case of infant-directed speech (IDS) and adult-directed speech (ADS) analysis. First, we manually and automatically annotated audio quality of utterances extracted from two corpora of child-centred long-form recordings (in English and French). We then compared acoustic features of IDS and ADS in an in-lab dataset and across different audio quality subsets of naturalistic data. Finally, we assessed how the audio quality and recording environment may change the conclusions of a modelling analysis using a recent self-supervised learning model. Our results show that the use of modest and high audio quality naturalistic speech data result in largely similar conclusions on IDS and ADS in terms of acoustic analyses and modelling experiments. We also found that an automatic sound quality assessment tool can be used to screen out useful parts of long-form recordings for a closer analysis with comparable results to that of manual quality annotation.|
